{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fe2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5815bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb008f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 5)) (3.1.40)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 8)) (4.8.1.78)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 16)) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: ultralytics>=8.0.147 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 18)) (8.0.209)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 42)) (68.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (8.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#go to yolov5 folder and install requirements.txt \n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bc96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "# install yolov5 then other libraries will solve start\n",
    "sys.path.append('D:\\Shravtek\\Engraving_text_ocr\\engraved_ocr_complete_source\\yolov5')\n",
    "import torch\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.torch_utils import select_device\n",
    "from utils.dataloaders import LoadImages\n",
    "from utils.general import non_max_suppression,Profile,scale_boxes,xyxy2xywh\n",
    "from pathlib import Path\n",
    "from utils.plots import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e88062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for gitpython>=3.1.30 from https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (1.24.3)\n",
      "Collecting opencv-python>=4.1.1 (from -r requirements.txt (line 8))\n",
      "  Obtaining dependency information for opencv-python>=4.1.1 from https://files.pythonhosted.org/packages/38/d2/3e8c13ffc37ca5ebc6f382b242b44acb43eb489042e1728407ac3904e72f/opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 16)) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
      "  Obtaining dependency information for ultralytics>=8.0.147 from https://files.pythonhosted.org/packages/9a/60/2bfc23a2ba1819305ccea076fdd8d8cd67190ab9d20a9838e5b7b731367c/ultralytics-8.0.209-py3-none-any.whl.metadata\n",
      "  Downloading ultralytics-8.0.209-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 42)) (68.0.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (8.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "   ---------------------------------------- 0.0/190.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 190.6/190.6 kB 12.0 MB/s eta 0:00:00\n",
      "Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Downloading ultralytics-8.0.209-py3-none-any.whl (645 kB)\n",
      "   ---------------------------------------- 0.0/645.2 kB ? eta -:--:--\n",
      "   --------------------------------------  645.1/645.2 kB 13.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 645.2/645.2 kB 13.5 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, opencv-python, gitdb, thop, gitpython, ultralytics\n",
      "Successfully installed gitdb-4.0.11 gitpython-3.1.40 opencv-python-4.8.1.78 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts ultralytics.exe and yolo.exe are installed in 'C:\\Users\\shan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e83d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import filters\n",
    "\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.ndimage import label, binary_fill_holes\n",
    "\n",
    "import string\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor,Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3284bc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 322 layers, 86180143 parameters, 0 gradients, 203.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "weights = 'D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/best.pt'\n",
    "dnn= False\n",
    "fp16=False\n",
    "data = 'D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/data.yaml'\n",
    "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=fp16)\n",
    "imgsz=(640, 640)\n",
    "pt = model.pt\n",
    "model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087084a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7854a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_results(image_path,model):\n",
    "    source = image_path\n",
    "    imgsz=(640, 640)\n",
    "    stride = model.stride\n",
    "    pt = model.pt\n",
    "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "    conf_thres = 0.25\n",
    "    iou_thres=0.45\n",
    "    classes = None\n",
    "    agnostic_nms = False\n",
    "    max_det = 1000\n",
    "    webcam = False\n",
    "    save_dir = Path('D:/Upwork/KS/MOHIT/')\n",
    "    save_crop = False\n",
    "    line_thickness = 3\n",
    "    names = model.names\n",
    "\n",
    "    total_detections = []\n",
    "    seen, windows, dt = 0, [], (Profile(), Profile(), Profile())\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "            with dt[0]:\n",
    "                im = torch.from_numpy(im).to(model.device)\n",
    "                im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "                im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "                if len(im.shape) == 3:\n",
    "                    im = im[None]  # expand for batch dim\n",
    "\n",
    "            # Inference\n",
    "            with dt[1]:\n",
    "                visualize = False\n",
    "                augment = False\n",
    "                pred = model(im, augment=augment, visualize=visualize)\n",
    "\n",
    "            # NMS\n",
    "            with dt[2]:\n",
    "                pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "            for i, det in enumerate(pred):  # per image\n",
    "                seen += 1\n",
    "                if webcam:  # batch_size >= 1\n",
    "                    p, im0, frame = path[i], im0s[i].copy(), dataset.count\n",
    "                    s += f'{i}: '\n",
    "                else:\n",
    "                    p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "\n",
    "                p = Path(p)  # to Path\n",
    "                save_path = str(save_dir / p.name)  # im.jpg\n",
    "                #txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "                txt_path = str(save_dir / p.stem)\n",
    "                s += '%gx%g ' % im.shape[2:]  # print string\n",
    "                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "                imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "                annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "                if len(det):\n",
    "                    # Rescale boxes from img_size to im0 size\n",
    "                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                    # Print results\n",
    "                    for c in det[:, 5].unique():\n",
    "                        n = (det[:, 5] == c).sum()  # detections per class\n",
    "                        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                    # Write results\n",
    "                    save_conf = True\n",
    "                    for *xyxy, conf, cls in reversed(det):\n",
    "                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                            line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "    #                         with open(f'{txt_path}.txt', 'a') as f:\n",
    "    #                             f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "                            total_detections.append(line)\n",
    "        \n",
    "    converted_detections = [tuple(value.item() if isinstance(value, torch.Tensor) else value for value in item) for item in total_detections]\n",
    "        \n",
    "    return converted_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3937e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4 s\n",
      "Wall time: 1.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0,\n",
       "  0.4954427182674408,\n",
       "  0.6581307649612427,\n",
       "  0.2200520783662796,\n",
       "  0.1032986119389534,\n",
       "  0.8900173306465149),\n",
       " (0.0,\n",
       "  0.5552300214767456,\n",
       "  0.24334490299224854,\n",
       "  0.2345920205116272,\n",
       "  0.10995370149612427,\n",
       "  0.9114524722099304)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_yolo_results('D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/images/00003_1007B/IMG20230717185759.jpg',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f40684ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(image_path, detections):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    bounding_boxes = []\n",
    "    \n",
    "    for cls, x, y, w, h, confidence in detections:\n",
    "        cls = int(cls)\n",
    "        left = int((x - w/2) * image.shape[1]) - 10\n",
    "        top = int((y - h/2) * image.shape[0]) - 10\n",
    "        width = int(w * image.shape[1]) + 20\n",
    "        height = int(h * image.shape[0]) + 20\n",
    "        \n",
    "        bounding_boxes.append({\n",
    "            'class': cls,\n",
    "            'left': left,\n",
    "            'top': top,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "    \n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8cf3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = get_bboxes('D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/images/00003_1007B/IMG20230717185759.jpg',\n",
    "                        get_yolo_results('D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/images/00003_1007B/IMG20230717185759.jpg'\n",
    "                                         ,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd0f322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 1, 'left': 1766, 'top': 2085, 'width': 1033, 'height': 377},\n",
       " {'class': 0, 'left': 2007, 'top': 640, 'width': 1101, 'height': 399}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a15f2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/images/00003_1007B/IMG20230717185759.jpg')\n",
    "cropped_img = img[detections[1]['top']:detections[1]['top']+detections[1]['height'],detections[1]['left']:detections[1]['left']+detections[1]['width']]\n",
    "plt.imshow(cropped_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "219856b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bbox_area(bbox):\n",
    "    width = bbox['width']\n",
    "    height = bbox['height']\n",
    "    return width * height\n",
    "\n",
    "def remove_lowest_area_bbox(detections):\n",
    "    if len(detections) <= 2:\n",
    "        return detections\n",
    "\n",
    "    areas = [calculate_bbox_area(bbox) for bbox in detections]\n",
    "    min_area_index = areas.index(min(areas))\n",
    "    \n",
    "    # Return detections without the detection with the lowest area\n",
    "    return detections[:min_area_index] + detections[min_area_index + 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e675cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 1, 'left': 1766, 'top': 2085, 'width': 1033, 'height': 377},\n",
       " {'class': 0, 'left': 2007, 'top': 640, 'width': 1101, 'height': 399}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_lowest_area_bbox(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70b0abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the checkpoint\n",
    "checkpoint_path = 'D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/epoch=16-step=2086-val_accuracy=100.0000-val_NED=100.0000.ckpt'\n",
    "\n",
    "# Define the model parameters\n",
    "model_args = {\n",
    "    'data_root': 'data',\n",
    "    'batch_size': 1,  # Set batch size to 1 for inference on singular images\n",
    "    'num_workers': 4,\n",
    "    'cased': False,\n",
    "    'punctuation': False,\n",
    "    'new': False,  # Set to True if you want to evaluate on new benchmark datasets\n",
    "    'rotation': 0,\n",
    "    'device': 'cpu'  # Use 'cuda' or 'cpu' depending on your environment\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "212c83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\shan/.cache\\torch\\hub\\baudm_parseq_main\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Missing dependencies: pytorch_lightning, timm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model checkpoint\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_ocr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaudm/parseq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparseq\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Example: Replace with your model loading code\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_ocr\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path,map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m model_ocr\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\hub.py:566\u001b[0m, in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    563\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    564\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39mverbose, skip_validation\u001b[38;5;241m=\u001b[39mskip_validation)\n\u001b[1;32m--> 566\u001b[0m model \u001b[38;5;241m=\u001b[39m _load_local(repo_or_dir, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\hub.py:594\u001b[0m, in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     hubconf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hubconf_dir, MODULE_HUBCONF)\n\u001b[0;32m    592\u001b[0m     hub_module \u001b[38;5;241m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m--> 594\u001b[0m     entry \u001b[38;5;241m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[0;32m    595\u001b[0m     model \u001b[38;5;241m=\u001b[39m entry(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\hub.py:343\u001b[0m, in \u001b[0;36m_load_entry_from_hubconf\u001b[1;34m(m, model)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid input: model should be a string of function name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Note that if a missing dependency is imported at top level of hubconf, it will\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# throw before this function. It's a chicken and egg situation where we have to\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# load hubconf to know what're the dependencies, but to import hubconf it requires\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# a missing package. This is fine, Python will throw proper error message for users.\u001b[39;00m\n\u001b[1;32m--> 343\u001b[0m _check_dependencies(m)\n\u001b[0;32m    345\u001b[0m func \u001b[38;5;241m=\u001b[39m _load_attr_from_module(m, model)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\hub.py:332\u001b[0m, in \u001b[0;36m_check_dependencies\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m    330\u001b[0m missing_deps \u001b[38;5;241m=\u001b[39m [pkg \u001b[38;5;28;01mfor\u001b[39;00m pkg \u001b[38;5;129;01min\u001b[39;00m dependencies \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _check_module_exists(pkg)]\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_deps):\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing dependencies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_deps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Missing dependencies: pytorch_lightning, timm"
     ]
    }
   ],
   "source": [
    "# Load the model checkpoint\n",
    "model_ocr = torch.hub.load('baudm/parseq', 'parseq', pretrained=True,map_location=torch.device('cpu'))  # Example: Replace with your model loading code\n",
    "model_ocr.load_state_dict(torch.load(checkpoint_path,map_location=torch.device('cpu'))['state_dict'])\n",
    "model_ocr.eval()\n",
    "model_ocr.to(model_args['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "376cc389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (8.0.209)\n",
      "Requirement already satisfied: dill in c:\\programdata\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Collecting pytorch-lightning==1.9.5\n",
      "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "Collecting timm\n",
      "  Obtaining dependency information for timm from https://files.pythonhosted.org/packages/f0/1e/05287cb8984229d101874433df472b1fa3dcd6f746ccb6e8a26c7deeb1c7/timm-0.9.10-py3-none-any.whl.metadata\n",
      "  Downloading timm-0.9.10-py3-none-any.whl.metadata (59 kB)\n",
      "     ---------------------------------------- 0.0/59.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 59.8/59.8 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.9.5) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from pytorch-lightning==1.9.5) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.9.5) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.9.5) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.9.5) (2023.3.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.5)\n",
      "  Obtaining dependency information for torchmetrics>=0.7.0 from https://files.pythonhosted.org/packages/a3/88/cc27059747ddecff744826e38014822023cbfff4ca079a6ee9a96602dd0b/torchmetrics-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.9.5) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-lightning==1.9.5) (4.7.1)\n",
      "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning==1.9.5)\n",
      "  Obtaining dependency information for lightning-utilities>=0.6.0.post0 from https://files.pythonhosted.org/packages/46/ee/8641eeb6a062f383b7d6875604e1f3f83bd2c93a0b4dbcabd3150b32de6e/lightning_utilities-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached lightning_utilities-0.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\shan\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Collecting huggingface-hub (from timm)\n",
      "  Obtaining dependency information for huggingface-hub from https://files.pythonhosted.org/packages/65/cc/2891260847777eb9aaca278aaf3f846c9ff8ea1351643a4f33ff26d5d213/huggingface_hub-0.19.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Obtaining dependency information for safetensors from https://files.pythonhosted.org/packages/da/33/f7437e23b0bb3f14014ab60de5948ca2b5187031e955e2db2fa872e35a3c/safetensors-0.4.0-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.0-cp311-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning==1.9.5) (0.4.6)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub (from timm)\n",
      "  Obtaining dependency information for huggingface-hub from https://files.pythonhosted.org/packages/64/8c/2766ce7e136eeb8b4d502e68eb1fe65342ee1aaf9129ec1c0838e5a4f0cb/huggingface_hub-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.5) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->pytorch-lightning==1.9.5) (1.3.0)\n",
      "Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 21.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 20.4 MB/s eta 0:00:00\n",
      "Using cached lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
      "   ---------------------------------------- 0.0/805.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 805.2/805.2 kB 25.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 295.0/295.0 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.0-cp311-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 277.4/277.4 kB ? eta 0:00:00\n",
      "Installing collected packages: safetensors, lightning-utilities, huggingface-hub, torchmetrics, timm, pytorch-lightning\n",
      "Successfully installed huggingface-hub-0.17.3 lightning-utilities-0.9.0 pytorch-lightning-1.9.5 safetensors-0.4.0 timm-0.9.10 torchmetrics-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\shan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics dill pytorch-lightning==1.9.5 timm nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e41f3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\shan/.cache\\torch\\hub\\baudm_parseq_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PARSeq(\n",
       "  (encoder): Encoder(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 384, kernel_size=(4, 8), stride=(4, 8))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_q): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_c): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): Linear(in_features=384, out_features=95, bias=True)\n",
       "  (text_embed): TokenEmbedding(\n",
       "    (embedding): Embedding(97, 384)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model checkpoint\n",
    "model_ocr = torch.hub.load('baudm/parseq', 'parseq', pretrained=True,map_location=torch.device('cpu'))  # Example: Replace with your model loading code\n",
    "model_ocr.load_state_dict(torch.load(checkpoint_path,map_location=torch.device('cpu'))['state_dict'])\n",
    "model_ocr.eval()\n",
    "model_ocr.to(model_args['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "159e5736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_inference(model, image):\n",
    "    transform = ToTensor()\n",
    "    resize = resize = Resize((32, 128))   # Resize the image to match the model's input size\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = resize(image)  # Resize the image\n",
    "    image_tensor = transform(image).unsqueeze(0).to(model_args['device'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        # Process the output as needed\n",
    "\n",
    "    return output\n",
    "\n",
    "def ocr_text(model,image):\n",
    "    inference_result = perform_inference(model, image)\n",
    "    # Greedy decoding\n",
    "    pred = inference_result.softmax(-1)\n",
    "    label, confidence = model_ocr.tokenizer.decode(pred)\n",
    "    return (label[0],[\"{:.2%}\".format(value) for value in confidence[0].tolist()[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c6f97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('D:/Shravtek/Engraving_text_ocr/engraved_ocr_complete_source/images/synthetic_dataset/0-500/1-100/94.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad686eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('00094', ['100.00%', '100.00%', '100.00%', '100.00%', '100.00%'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_text(model_ocr,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05686e4",
   "metadata": {},
   "source": [
    "###### Testing Model on all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9478e9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                               | 0/6 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                               | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                                               | 0/6 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "filenames_list = []\n",
    "expected_Dot_Peening_Text_list = []\n",
    "predicted_Dot_Peening_Text_list = []\n",
    "expected_Machine_Peening_Text_list = []\n",
    "predicted_Machine_Peening_Text_list = []\n",
    "for curdir in tqdm.tqdm(os.listdir('/home/ubuntu/mohit/OCR-FineTuning/parseq/data/data2/actual_cam/')):\n",
    "    for curfile in tqdm.tqdm(glob.glob(f'/home/ubuntu/mohit/OCR-FineTuning/parseq/data/data2/actual_cam/{curdir}/*.jpg')):\n",
    "        img = img = cv2.imread(curfile)\n",
    "        expected_texts = curdir.split('_')\n",
    "        detections = get_bboxes(curfile, get_yolo_results(curfile,model))\n",
    "#         if len(detections) > 2:\n",
    "#             break\n",
    "        detections = remove_lowest_area_bbox(detections)\n",
    "        for detection in detections:\n",
    "            if detection['class'] == 0:\n",
    "                cropped_img = img[detection['top']:detection['top']+detection['height'],detection['left']:detection['left']+detection['width']]\n",
    "                predicted_Dot_Peening_Text_list.append(ocr_text(model_ocr,cropped_img))\n",
    "                #predicted_Dot_Peening_Text_list.append(ocr.ocr(sharpen_image(cropped_img))[0][0][1][0].replace(' ',''))\n",
    "            else:\n",
    "                cropped_img = img[detection['top']:detection['top']+detection['height'],detection['left']:detection['left']+detection['width']]\n",
    "                predicted_Machine_Peening_Text_list.append(ocr_text(model_ocr,cropped_img))\n",
    "        \n",
    "        filenames_list.append(curfile)\n",
    "        expected_Dot_Peening_Text_list.append(expected_texts[1])\n",
    "        expected_Machine_Peening_Text_list.append(expected_texts[0])\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d915c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>expected_Dot_Peening</th>\n",
       "      <th>predicted_Dot_Peening</th>\n",
       "      <th>expected_Machine_Peening</th>\n",
       "      <th>predicted_Machine_Peening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/mohit/OCR-FineTuning/parseq/data/...</td>\n",
       "      <td>00324</td>\n",
       "      <td>00324</td>\n",
       "      <td>1006C1</td>\n",
       "      <td>1006C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames expected_Dot_Peening  \\\n",
       "0  /home/ubuntu/mohit/OCR-FineTuning/parseq/data/...                00324   \n",
       "\n",
       "  predicted_Dot_Peening expected_Machine_Peening predicted_Machine_Peening  \n",
       "0                 00324                   1006C1                    1006C1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'filenames':filenames_list,'expected_Dot_Peening':expected_Dot_Peening_Text_list,\n",
    "                  'predicted_Dot_Peening':predicted_Dot_Peening_Text_list,\n",
    "                   'expected_Machine_Peening':expected_Machine_Peening_Text_list,\n",
    "                   'predicted_Machine_Peening':predicted_Machine_Peening_Text_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce26e000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overall_Match\n",
       "True    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comparison columns\n",
    "df['Dot_Peening_Match'] = df.apply(\n",
    "    lambda row: row['expected_Dot_Peening'] == row['predicted_Dot_Peening'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['Machine_Peening_Match'] = df.apply(\n",
    "    lambda row: row['expected_Machine_Peening'] == row['predicted_Machine_Peening'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create an overall match column\n",
    "df['Overall_Match'] = df['Dot_Peening_Match'] & df['Machine_Peening_Match']\n",
    "df['Overall_Match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8364d217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filenames                    object\n",
       "expected_Dot_Peening         object\n",
       "predicted_Dot_Peening        object\n",
       "expected_Machine_Peening     object\n",
       "predicted_Machine_Peening    object\n",
       "Dot_Peening_Match              bool\n",
       "Machine_Peening_Match          bool\n",
       "Overall_Match                  bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "617c9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('latest_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb85af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
